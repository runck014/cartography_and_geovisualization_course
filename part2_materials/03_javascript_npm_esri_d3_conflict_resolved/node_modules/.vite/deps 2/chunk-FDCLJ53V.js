import {
  P,
  a2 as a,
  d2 as d,
  e3 as e4,
  e4 as e5,
  f,
  f2,
  g,
  l,
  o2 as o6,
  o3 as o7,
  p3 as p,
  s as s3,
  s2 as s4,
  t as t3,
  w
} from "./chunk-PFCCTBQ6.js";
import {
  e as e3
} from "./chunk-JW4HK5OB.js";
import {
  e as e2,
  o as o8,
  s as s2
} from "./chunk-PVFZLQ5G.js";
import {
  o as o4,
  t as t2
} from "./chunk-IWXHREP5.js";
import {
  n as n2
} from "./chunk-HRP7POO2.js";
import {
  o as o5
} from "./chunk-JQJITHTO.js";
import {
  o as o3,
  r as r3
} from "./chunk-6LGJYARD.js";
import {
  e
} from "./chunk-L7OHH2HW.js";
import {
  n
} from "./chunk-ECMDQ4LS.js";
import {
  o as o2,
  r as r2
} from "./chunk-LP6TMAPE.js";
import {
  o
} from "./chunk-CTU2XDPA.js";
import {
  r,
  s
} from "./chunk-AFULL6KA.js";
import {
  t
} from "./chunk-DRBJFCLQ.js";

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUD.glsl.js
var p2 = 0.5;
function d2(d3, u) {
  d3.include(s3), d3.attributes.add(e.POSITION, "vec3"), d3.attributes.add(e.NORMAL, "vec3"), d3.attributes.add(e.CENTEROFFSETANDDISTANCE, "vec4");
  const v = d3.vertex;
  d(v, u), f(v, u), v.uniforms.add(new e3("viewport", (e6, t5) => t5.camera.fullViewport), new o5("polygonOffset", (e6) => e6.shaderPolygonOffset), new o5("cameraGroundRelative", (e6, t5) => t5.camera.aboveGround ? 1 : -1)), u.hasVerticalOffset && f2(v), v.constants.add("smallOffsetAngle", "float", 0.984807753012208), v.code.add(o3`struct ProjectHUDAux {
vec3 posModel;
vec3 posView;
vec3 vnormal;
float distanceToCamera;
float absCosAngle;
};`), v.code.add(o3`
    float applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {
      float pointGroundSign = ${u.terrainDepthTest ? o3.float(0) : o3`sign(pointGroundDistance)`};
      if (pointGroundSign == 0.0) {
        pointGroundSign = cameraGroundRelative;
      }

      // cameraGroundRelative is -1 if camera is below ground, 1 if above ground
      // groundRelative is 1 if both camera and symbol are on the same side of the ground, -1 otherwise
      float groundRelative = cameraGroundRelative * pointGroundSign;

      // view angle dependent part of polygon offset emulation: we take the absolute value because the sign that is
      // dropped is instead introduced using the ground-relative position of the symbol and the camera
      if (polygonOffset > .0) {
        float cosAlpha = clamp(absCosAngle, 0.01, 1.0);
        float tanAlpha = sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;
        float factor = (1.0 - tanAlpha / viewport[2]);

        // same side of the terrain
        if (groundRelative > 0.0) {
          posView *= factor;
        }
        // opposite sides of the terrain
        else {
          posView /= factor;
        }
      }

      return groundRelative;
    }
  `), u.draped && !u.hasVerticalOffset || p(v), u.draped || (v.uniforms.add(new o5("perDistancePixelRatio", (e6, t5) => Math.tan(t5.camera.fovY / 2) / (t5.camera.fullViewport[2] / 2))), v.code.add(o3`
    void applyHUDVerticalGroundOffset(vec3 normalModel, inout vec3 posModel, inout vec3 posView) {
      float distanceToCamera = length(posView);

      // Compute offset in world units for a half pixel shift
      float pixelOffset = distanceToCamera * perDistancePixelRatio * ${o3.float(p2)};

      // Apply offset along normal in the direction away from the ground surface
      vec3 modelOffset = normalModel * cameraGroundRelative * pixelOffset;

      // Apply the same offset also on the view space position
      vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;

      posModel += modelOffset;
      posView += viewOffset;
    }
  `)), u.screenCenterOffsetUnitsEnabled && w(v), u.hasScreenSizePerspective && o7(v), v.code.add(o3`
    vec4 projectPositionHUD(out ProjectHUDAux aux) {
      vec3 centerOffset = centerOffsetAndDistance.xyz;
      float pointGroundDistance = centerOffsetAndDistance.w;

      aux.posModel = position;
      aux.posView = (view * vec4(aux.posModel, 1.0)).xyz;
      aux.vnormal = normal;
      ${u.draped ? "" : "applyHUDVerticalGroundOffset(aux.vnormal, aux.posModel, aux.posView);"}

      // Screen sized offset in world space, used for example for line callouts
      // Note: keep this implementation in sync with the CPU implementation, see
      //   - MaterialUtil.verticalOffsetAtDistance
      //   - HUDMaterial.applyVerticalOffsetTransformation

      aux.distanceToCamera = length(aux.posView);

      vec3 viewDirObjSpace = normalize(cameraPosition - aux.posModel);
      float cosAngle = dot(aux.vnormal, viewDirObjSpace);

      aux.absCosAngle = abs(cosAngle);

      ${u.hasScreenSizePerspective && (u.hasVerticalOffset || u.screenCenterOffsetUnitsEnabled) ? "vec3 perspectiveFactor = screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);" : ""}

      ${u.hasVerticalOffset ? u.hasScreenSizePerspective ? "float verticalOffsetScreenHeight = applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);" : "float verticalOffsetScreenHeight = verticalOffset.x;" : ""}

      ${u.hasVerticalOffset ? o3`
            float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);
            vec3 modelOffset = aux.vnormal * worldOffset;
            aux.posModel += modelOffset;
            vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;
            aux.posView += viewOffset;
            // Since we elevate the object, we need to take that into account
            // in the distance to ground
            pointGroundDistance += worldOffset;` : ""}

      float groundRelative = applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);

      ${u.screenCenterOffsetUnitsEnabled ? "" : o3`
            // Apply x/y in view space, but z in screen space (i.e. along posView direction)
            aux.posView += vec3(centerOffset.x, centerOffset.y, 0.0);

            // Same material all have same z != 0.0 condition so should not lead to
            // branch fragmentation and will save a normalization if it's not needed
            if (centerOffset.z != 0.0) {
              aux.posView -= normalize(aux.posView) * centerOffset.z;
            }
          `}

      vec4 posProj = proj * vec4(aux.posView, 1.0);

      ${u.screenCenterOffsetUnitsEnabled ? u.hasScreenSizePerspective ? "float centerOffsetY = applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);" : "float centerOffsetY = centerOffset.y;" : ""}

      ${u.screenCenterOffsetUnitsEnabled ? "posProj.xy += vec2(centerOffset.x, centerOffsetY) * pixelRatio * 2.0 / viewport.zw * posProj.w;" : ""}

      // constant part of polygon offset emulation
      posProj.z -= groundRelative * polygonOffset * posProj.w;
      return posProj;
    }
  `);
}

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/AlignPixel.glsl.js
function o9(o10) {
  o10.uniforms.add(new s4("alignPixelEnabled", (e6, i) => i.alignPixelEnabled)), o10.code.add(o3`vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {
if (!alignPixelEnabled)
return clipCoord;
vec2 xy = vec2(0.500123) + 0.5 * clipCoord.xy / clipCoord.w;
vec2 pixelSz = vec2(1.0) / widthHeight;
vec2 ij = (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;
vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;
return vec4(result, clipCoord.zw);
}`), o10.code.add(o3`vec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {
if (!alignPixelEnabled)
return clipCoord;
vec2 xy = vec2(0.5) + 0.5 * clipCoord.xy / clipCoord.w;
vec2 pixelSz = vec2(1.0) / widthHeight;
vec2 ij = floor((xy + 0.5 * pixelSz) * widthHeight) * pixelSz;
vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;
return vec4(result, clipCoord.zw);
}`);
}

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUDOcclusionPass.glsl.js
function r4(r5, i) {
  const { vertex: p3, fragment: s5 } = r5;
  r5.include(a, i), p3.include(o9), i.terrainDepthTest && r5.varyings.add("depth", "float"), p3.main.add(o3`
    vec4 posProjCenter;
    if (dot(position, position) > 0.0) {
      // Render single point to center of the pixel to avoid subpixel filtering to affect the marker color
      ProjectHUDAux projectAux;
      vec4 posProj = projectPositionHUD(projectAux);
      posProjCenter = alignToPixelCenter(posProj, viewport.zw);

      ${i.terrainDepthTest ? o3`depth = projectAux.posView.z;` : ""}
      vec3 vpos = projectAux.posModel;
      if (rejectBySlice(vpos)) {
        // Project out of clip space
        posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);
      }

    } else {
      // Project out of clip space
      posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);
    }

    gl_Position = posProjCenter;
    gl_PointSize = 1.0;
  `), s5.main.add(o3`fragColor = vec4(1);
if(terrainDepthTest(depth)) {
fragColor.g = 0.5;
}`);
}

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUDRenderStyle.js
var c;
!function(c2) {
  c2[c2.Occluded = 0] = "Occluded", c2[c2.NotOccluded = 1] = "NotOccluded", c2[c2.Both = 2] = "Both", c2[c2.COUNT = 3] = "COUNT";
}(c || (c = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/hud/HUDVisibility.glsl.js
function t4(t5) {
  t5.vertex.uniforms.add(new o5("renderTransparentlyOccludedHUD", (e6, o10) => o10.hudRenderStyle === c.Occluded ? 1 : o10.hudRenderStyle === c.NotOccluded ? 0 : 0.75), new e3("viewport", (e6, r5) => r5.camera.fullViewport), new s2("hudVisibilityTexture", (e6, r5) => {
    var _a;
    return (_a = r5.hudVisibility) == null ? void 0 : _a.getTexture();
  })), t5.vertex.include(o9), t5.vertex.code.add(o3`bool testHUDVisibility(vec4 posProj) {
vec4 posProjCenter = alignToPixelCenter(posProj, viewport.zw);
vec4 occlusionPixel = texture(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w);
if (renderTransparentlyOccludedHUD > 0.5) {
return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g * renderTransparentlyOccludedHUD < 1.0;
}
return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g == 1.0;
}`);
}

// node_modules/@arcgis/core/chunks/HUDMaterial.glsl.js
var L = { occludedFadeFactor: 0.6 };
function T(o10) {
  const r5 = new o8(), T2 = o10.signedDistanceFieldEnabled;
  if (r5.include(d2, o10), r5.include(P, o10), o10.occlusionPass) return r5.include(r4, o10), r5;
  const { vertex: M2, fragment: H2 } = r5;
  r5.include(s3), r5.include(l, o10), r5.include(e4, o10), r5.include(t4), H2.include(t2), H2.include(e5), r5.varyings.add("vcolor", "vec4"), r5.varyings.add("vtc", "vec2"), r5.varyings.add("vsize", "vec2"), r5.varyings.add("voccluded", "float"), M2.uniforms.add(new e3("viewport", (e6, o11) => o11.camera.fullViewport), new e2("screenOffset", (o11, r6) => o2(R, 2 * o11.screenOffset[0] * r6.camera.pixelRatio, 2 * o11.screenOffset[1] * r6.camera.pixelRatio)), new e2("anchorPosition", (e6) => E(e6)), new e3("materialColor", (e6) => e6.color), new o5("materialRotation", (e6) => e6.rotation)), w(M2), T2 && (M2.uniforms.add(new e3("outlineColor", (e6) => e6.outlineColor)), H2.uniforms.add(new e3("outlineColor", (e6) => B(e6) ? e6.outlineColor : s), new o5("outlineSize", (e6) => B(e6) ? e6.outlineSize : 0))), o10.horizonCullingEnabled && M2.uniforms.add(new o4("pointDistanceSphere", (e6, o11) => {
    const r6 = o11.camera.eye, i = e6.origin;
    return r(i[0] - r6[0], i[1] - r6[1], i[2] - r6[2], t.radius);
  })), o10.pixelSnappingEnabled && M2.include(o9), o10.hasScreenSizePerspective && (t3(M2), o7(M2)), o10.debugDrawLabelBorder && r5.varyings.add("debugBorderCoords", "vec4"), r5.attributes.add(e.UV0, "vec2"), r5.attributes.add(e.COLOR, "vec4"), r5.attributes.add(e.SIZE, "vec2"), r5.attributes.add(e.ROTATION, "float"), r5.attributes.add(e.FEATUREATTRIBUTE, "vec4"), M2.code.add(o10.horizonCullingEnabled ? o3`bool behindHorizon(vec3 posModel) {
vec3 camToEarthCenter = pointDistanceSphere.xyz - localOrigin;
vec3 camToPos = pointDistanceSphere.xyz + posModel;
float earthRadius = pointDistanceSphere.w;
float a = dot(camToPos, camToPos);
float b = dot(camToPos, camToEarthCenter);
float c = dot(camToEarthCenter, camToEarthCenter) - earthRadius * earthRadius;
return  b > 0.0 && b < a && b * b  > a * c;
}` : o3`bool behindHorizon(vec3 posModel) { return false; }`), M2.main.add(o3`
      ProjectHUDAux projectAux;
      vec4 posProj = projectPositionHUD(projectAux);
      forwardObjectAndLayerIdColor();

      if (rejectBySlice(projectAux.posModel)) {
        // Project outside of clip plane
        gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
        return;
      }

      if (behindHorizon(projectAux.posModel)) {
        // Project outside of clip plane
        gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
        return;
      }

      vec2 inputSize;
      ${r3(o10.hasScreenSizePerspective, o3`
          inputSize = screenSizePerspectiveScaleVec2(size, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspective);
          vec2 screenOffsetScaled = screenSizePerspectiveScaleVec2(screenOffset, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);`, o3`
          inputSize = size;
          vec2 screenOffsetScaled = screenOffset;`)}
      ${r3(o10.vvSize, o3`inputSize *= vvScale(featureAttribute).xx;`)}

      vec2 combinedSize = inputSize * pixelRatio;
      vec4 quadOffset = vec4(0.0);
      bool visible = testHUDVisibility(posProj);
      voccluded = visible ? 0.0 : 1.0;
    `);
  const U = o3`
      vec2 uv01 = floor(uv0);
      vec2 uv = uv0 - uv01;
      quadOffset.xy = (uv01 - anchorPosition) * 2.0 * combinedSize;

      ${r3(o10.hasRotation, o3`
          float angle = radians(materialRotation + rotation);
          float cosAngle = cos(angle);
          float sinAngle = sin(angle);
          mat2 rotate = mat2(cosAngle, -sinAngle, sinAngle,  cosAngle);

          quadOffset.xy = rotate * quadOffset.xy;
        `)}

      quadOffset.xy = (quadOffset.xy + screenOffsetScaled) / viewport.zw * posProj.w;
  `, V = o10.pixelSnappingEnabled ? T2 ? o3`posProj = alignToPixelOrigin(posProj, viewport.zw) + quadOffset;` : o3`posProj += quadOffset;
if (inputSize.x == size.x) {
posProj = alignToPixelOrigin(posProj, viewport.zw);
}` : o3`posProj += quadOffset;`;
  M2.main.add(o3`
    ${r3(o10.occlusionTestEnabled, o3`
      if (!visible) {
        vtc = vec2(0.0);
        ${r3(o10.debugDrawLabelBorder, "debugBorderCoords = vec4(0.5, 0.5, 1.5 / combinedSize);")}
        return;
      }`)}
    ${U}
    ${o10.vvColor ? "vcolor = interpolateVVColor(featureAttribute.y) * materialColor;" : "vcolor = color / 255.0 * materialColor;"}

    ${r3(o10.output === n2.ObjectAndLayerIdColor, o3`vcolor.a = 1.0;`)}

    bool alphaDiscard = vcolor.a < ${o3.float(o)};
    ${r3(T2, `alphaDiscard = alphaDiscard && outlineColor.a < ${o3.float(o)};`)}
    if (alphaDiscard) {
      // "early discard" if both symbol color (= fill) and outline color (if applicable) are transparent
      gl_Position = vec4(1e38, 1e38, 1e38, 1.0);
      return;
    } else {
      ${V}
      gl_Position = posProj;
    }

    vtc = uv;

    ${r3(o10.debugDrawLabelBorder, o3`debugBorderCoords = vec4(uv01, 1.5 / combinedSize);`)}
    vsize = inputSize;
  `), H2.uniforms.add(new s2("tex", (e6) => e6.texture)), o10.occludedFragmentFade && (H2.uniforms.add(new s2("depthMap", (e6, o11) => o11.mainDepth)), H2.uniforms.add(new o5("fadeFactor", () => L.occludedFadeFactor)));
  const _ = o10.debugDrawLabelBorder ? o3`(isBorder > 0.0 ? 0.0 : ${o3.float(o)})` : o3.float(o), I = o10.output === n2.Highlight, q = o3`
    ${r3(o10.debugDrawLabelBorder, o3`float isBorder = float(any(lessThan(debugBorderCoords.xy, debugBorderCoords.zw)) || any(greaterThan(debugBorderCoords.xy, 1.0 - debugBorderCoords.zw)));`)}

    ${r3(o10.sampleSignedDistanceFieldTexelCenter, o3`
      float txSize = float(textureSize(tex, 0).x);
      float texelSize = 1.0 / txSize;

      // Calculate how much we have to add/subtract to/from each texel to reach the size of an onscreen pixel
      vec2 scaleFactor = (vsize - txSize) * texelSize;
      vec2 samplePos = vtc + (vec2(1.0, -1.0) * texelSize) * scaleFactor;`, o3`vec2 samplePos = vtc;`)}

    ${T2 ? o3`
      vec4 fillPixelColor = vcolor;

      // Get distance and map it into [-0.5, 0.5]
      float d = rgba2float(texture(tex, samplePos)) - 0.5;

      // Distance in output units (i.e. pixels)
      float dist = d * vsize.x;

      // Create smooth transition from the icon into its outline
      float fillAlphaFactor = clamp(0.5 - dist, 0.0, 1.0);
      fillPixelColor.a *= fillAlphaFactor;

      if (outlineSize > 0.25) {
        vec4 outlinePixelColor = outlineColor;
        float clampedOutlineSize = min(outlineSize, 0.5*vsize.x);

        // Create smooth transition around outline
        float outlineAlphaFactor = clamp(0.5 - (abs(dist) - 0.5*clampedOutlineSize), 0.0, 1.0);
        outlinePixelColor.a *= outlineAlphaFactor;

        if (
          outlineAlphaFactor + fillAlphaFactor < ${_} ||
          fillPixelColor.a + outlinePixelColor.a < ${o3.float(o)}
        ) {
          discard;
        }

        // perform un-premultiplied over operator (see https://en.wikipedia.org/wiki/Alpha_compositing#Description)
        float compositeAlpha = outlinePixelColor.a + fillPixelColor.a * (1.0 - outlinePixelColor.a);
        vec3 compositeColor = vec3(outlinePixelColor) * outlinePixelColor.a +
          vec3(fillPixelColor) * fillPixelColor.a * (1.0 - outlinePixelColor.a);

        ${r3(!I, o3`fragColor = vec4(compositeColor, compositeAlpha);`)}
      } else {
        if (fillAlphaFactor < ${_}) {
          discard;
        }

        ${r3(!I, o3`fragColor = premultiplyAlpha(fillPixelColor);`)}
      }

      // visualize SDF:
      // fragColor = vec4(clamp(-dist/vsize.x*2.0, 0.0, 1.0), clamp(dist/vsize.x*2.0, 0.0, 1.0), 0.0, 1.0);
      ` : o3`
          vec4 texColor = texture(tex, vtc, -0.5);
          if (texColor.a < ${_}) {
            discard;
          }
          ${r3(!I, o3`fragColor = texColor * premultiplyAlpha(vcolor);`)}
          `}

    ${r3(o10.occludedFragmentFade && !I, o3`
        float zSample = texelFetch(depthMap, ivec2(gl_FragCoord.xy), 0).x;
        if (zSample < gl_FragCoord.z) {
          fragColor *= fadeFactor;
        }
        `)}

    ${r3(!I && o10.debugDrawLabelBorder, o3`fragColor = mix(fragColor, vec4(1.0, 0.0, 1.0, 1.0), isBorder * 0.5);`)}
  `;
  switch (o10.output) {
    case n2.Color:
      o10.oitPass === o6.ColorAlpha && (r5.outputs.add("fragColor", "vec4", 0), r5.outputs.add("fragAlpha", "float", 1)), H2.main.add(o3`
        ${q}
        ${r3(o10.oitPass === o6.FrontFace, o3`fragColor.rgb /= fragColor.a;`)}
        ${r3(o10.oitPass === o6.ColorAlpha, o3`fragAlpha = fragColor.a;`)}`);
      break;
    case n2.ObjectAndLayerIdColor:
      H2.main.add(o3`
        ${q}
        outputObjectAndLayerIdColor();`);
      break;
    case n2.Highlight:
      r5.include(g, o10), H2.main.add(o3`
        ${q}
        outputHighlight(voccluded == 1.0);`);
  }
  return r5;
}
function B(e6) {
  return e6.outlineColor[3] > 0 && e6.outlineSize > 0;
}
function E(e6, r5 = R) {
  return e6.textureIsSignedDistanceField ? M(e6.anchorPosition, e6.distanceFieldBoundingBox, r5) : r2(r5, e6.anchorPosition), r5;
}
function M(o10, r5, i) {
  null != r5 ? o2(i, o10[0] * (r5[2] - r5[0]) + r5[0], o10[1] * (r5[3] - r5[1]) + r5[1]) : o2(i, 0, 0);
}
var R = n();
var H = Object.freeze(Object.defineProperty({ __proto__: null, build: T, calculateAnchorPosForRendering: E, shaderSettings: L }, Symbol.toStringTag, { value: "Module" }));

export {
  p2 as p,
  L,
  T,
  E,
  H
};
//# sourceMappingURL=chunk-FDCLJ53V.js.map
