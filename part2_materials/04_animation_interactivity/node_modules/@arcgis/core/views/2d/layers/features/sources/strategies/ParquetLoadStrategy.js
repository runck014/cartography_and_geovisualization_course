/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.32/esri/copyright.txt for details.
*/
import{throwIfAborted as e}from"../../../../../../core/promiseUtils.js";import{difference as t,union as s}from"../../../../../../core/SetUtils.js";import i from"../../../../../../layers/support/FieldsIndex.js";import{ParquetFile as a}from"../../../../../../libs/parquet/parquet.js";import{ALoadStrategy as r}from"./ALoadStrategy.js";import{FeatureSnapshotSourceChunk as l}from"./chunks/FeatureSnapshotSourceChunk.js";import{FeatureSetReaderJSON as o}from"../../support/FeatureSetReaderJSON.js";import{FeatureSetReaderParquet as n}from"../../support/FeatureSetReaderParquet.js";class m extends r{constructor(e,t,s,i){super(i),this._service=e,this._metadata=t,this._schema=s,this._chunkId=0,this._files=[],this._availableFields=new Set(s.mutable.availableFields);const{geometryInfo:a}=this._service;if("location"===a.type)this._availableFields.add(a.latitudeFieldName),this._availableFields.add(a.longitudeFieldName);else if(null!=a.multiscale&&a.multiscale.levels.length>=1){const e=a.multiscale.levels[0];this._availableFields.add(e.column)}else this._availableFields.add(a.primaryFieldName)}destroy(){for(const e of this._files)e.destroy()}get about(){return{supportsDisplayFilter:!1,willQueryAllFeatures:!0,willQueryFullResolutionGeometry:!0}}async updateFields(e){await this._promise;const i=new Set(e),a=t(i,this._availableFields);this._availableFields=s(a,this._availableFields),a.size&&await Promise.all(this._files.map((e=>{const t=Array.from(a).map((t=>e.metadata.getFieldIndex(t)));return e.inner.updateChunks(new Uint16Array(t))})))}async load(e){return null==this._promise&&(this._promise=this._download().then((()=>{this._loadHigherResGeometry()}))),this._promise}unload(e){}async addParquetFile(e){this._insert(e)}async _loadHigherResGeometry(){const{geometryInfo:e}=this._service;if("geometry"===e.type){if(!(null!=e.multiscale&&e.multiscale.levels.length>=1))return;await this.updateFields([e.primaryFieldName])}const t=Array.from(this._store.chunks());this._store.clear();for(const s of t)this._store.insert(s);this._store.refresh()}async _insert(t){const s=await a.create(t,{geometryInfo:this._service.geometryInfo,outSpatialReference:this._service.outSpatialReference,getCustomParameters:()=>this._schema.mutable.dataFilter.customParameters}),{geometryInfo:r}=this._service;e(this._options);const{fields:o,timeZoneByFieldName:m}=this._service.metadata.fieldsIndex,d=o.map((e=>({...e,index:s.metadata.getFieldIndex(e.name)}))),h=i.fromJSON({fields:d,timeZoneByFieldName:m}),u=new Uint16Array(Array.from(this._availableFields.values()).map((e=>h.get(e)?.index)).filter((e=>null!=e)));await s.inner.readChunksWithCallback(u,(e=>{const t=this._chunkId++,s=new n(this._metadata,h,r,e,t),i=new l(s,null,t,!1);this._store.insert(i)})),this._files.push(s)}async _download(){try{await Promise.all(this._service.source.urls.map((e=>this._insert(e))));const e=new l(o.empty(this._metadata),null,-1,!0);this._store.insert(e)}catch(e){throw console.error(e),e}}}export{m as ParquetLoadStrategy};
